{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train data, images rows: 60000, label rows: 60000\n",
      "Load t10k data, images rows: 10000, label rows: 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "\n",
    "\n",
    "def load_mnist(path='dataset', kind='train'):\n",
    "    \"\"\"\n",
    "    A helper function to load the MNIST dataset.\n",
    "    :param path:\n",
    "    :param kind:\n",
    "    :return: images, labels\n",
    "    \"\"\"\n",
    "    path = os.path.join(os.getcwd(), path)\n",
    "    labels_path = os.path.join(path, '%s-labels.idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images.idx3-ubyte' % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n_labels = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, n_images, rows, columns = struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(n_images, rows * columns)\n",
    "    print('Load %s data, images rows: %d, label rows: %d' % (kind, n_images, n_labels))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "x_train, y_train = load_mnist(kind='train')\n",
    "x_test, y_test = load_mnist(kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = np.mean(x_train, axis=0)\n",
    "std_val = np.std(x_train)\n",
    "x_train_centered = (x_train - mean_val) / std_val\n",
    "x_test_centered = (x_test - mean_val) / std_val\n",
    "del x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=100, shuffle=False, random_seed=None):\n",
    "    \"\"\"\n",
    "    A helper function to generate batches of instances.\n",
    "    :param X: \n",
    "    :param y: \n",
    "    :param batch_size: \n",
    "    :param shuffle: \n",
    "    :param random_seed: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        idx = np.arange(y.shape[0])\n",
    "        random = np.random.RandomState(random_seed)\n",
    "        random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X[i:i + batch_size, :], y[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ConvNNModel(object):\n",
    "    def __init__(self, batch_size=100, epochs=20, dropout_rate=0.5,\n",
    "                 learning_rate=1e-4, shuffle=True, random_seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed\n",
    "        np.random.seed(random_seed)\n",
    "        g = tf.Graph()\n",
    "        with g.as_default():\n",
    "            tf.set_random_seed(random_seed)\n",
    "            self.build()\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            self.saver = tf.train.Saver()\n",
    "        self.sess = tf.Session(graph=g)\n",
    "        self.sess.run(self.init_op)\n",
    "\n",
    "    def build(self):\n",
    "        tf_x = tf.placeholder(tf.float32, shape=[None, 784], name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.int32, shape=[None], name='tf_y')\n",
    "        is_train = tf.placeholder(tf.bool, shape=(), name='is_train')\n",
    "        # reshape tf_x to 2d image\n",
    "        tf_x_2dimage = tf.reshape(tf_x, shape=[-1, 28, 28, 1])\n",
    "        # one hot coding on tf_y\n",
    "        y_onehot = tf.one_hot(indices=tf_y, depth=10, dtype=tf.float32)\n",
    "\n",
    "        # 1st layer: conv2d layer\n",
    "        h1 = tf.layers.conv2d(tf_x_2dimage, kernel_size=[5, 5], filters=32,\n",
    "                              padding='valid', activation=tf.nn.relu, name='h1')\n",
    "        # max pooling\n",
    "        h1_pool = tf.layers.max_pooling2d(h1, pool_size=[2, 2], strides=2, name='h1_pool')\n",
    "        print(h1)\n",
    "        print(h1_pool)\n",
    "\n",
    "        # 2nd layer: con2d layer\n",
    "        h2 = tf.layers.conv2d(h1_pool, kernel_size=[5, 5], filters=64,\n",
    "                              padding='valid', activation=tf.nn.relu, name='h2')\n",
    "        # max pooling\n",
    "        h2_pool = tf.layers.max_pooling2d(h2, pool_size=[2, 2], strides=2, name='h2_pool')\n",
    "        print(h2)\n",
    "        print(h2_pool)\n",
    "\n",
    "        # 3rd layer: dense\n",
    "        input_shape = h2_pool.get_shape().as_list()\n",
    "        n_input_units = np.prod(input_shape[1:])\n",
    "        h2_pool_flat = tf.reshape(h2_pool, shape=[-1, n_input_units], name='h2_pool_flat')\n",
    "        print(h2_pool_flat)\n",
    "        h3 = tf.layers.dense(h2_pool_flat, units=1024, activation=tf.nn.relu, name='h3')\n",
    "        # dropout\n",
    "        h3_drop = tf.layers.dropout(h3, training=is_train, rate=self.dropout_rate, name='h3_drop')\n",
    "        print(h3)\n",
    "        print(h3_drop)\n",
    "\n",
    "        # 4th layer: dense\n",
    "        logits = tf.layers.dense(h3_drop, units=10, activation=None, name='logits')\n",
    "        print(logits)\n",
    "\n",
    "        # prediction\n",
    "        prediction_labels = tf.cast(tf.argmax(logits, axis=1), tf.int32, name='prediction_labels')\n",
    "        print(prediction_labels)\n",
    "        # accuracy\n",
    "        correct = tf.equal(prediction_labels, tf_y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')\n",
    "        # loss function\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=y_onehot, logits=logits)\n",
    "        print(loss)\n",
    "        # optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        train_op = optimizer.minimize(loss=loss, name='train_op')\n",
    "\n",
    "    def train(self, training_set, validation_set):\n",
    "        x_data = np.array(training_set[0])\n",
    "        y_data = np.array(training_set[1])\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            batch = batch_generator(x_data, y_data, batch_size=self.batch_size, \n",
    "                                    shuffle=self.shuffle, random_seed=self.random_seed)\n",
    "            for _, (x, y) in enumerate(batch):\n",
    "                feed_dict = {'tf_x:0': x, 'tf_y:0': y, 'is_train:0': True}\n",
    "                self.sess.run('train_op', feed_dict=feed_dict)\n",
    "            x_validation = np.array(validation_set[0])\n",
    "            y_validation = np.array(validation_set[1])\n",
    "            feed_dict = {'tf_x:0': x_validation, 'tf_y:0': y_validation, 'is_train:0': False}\n",
    "            validation_accuracy = self.sess.run('accuracy:0', feed_dict=feed_dict)\n",
    "            print(\"Epoch: %2d validation accuracy: %6.2f\" % (epoch, (100 * validation_accuracy)))\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        feed_dict = {'tf_x:0': x, 'is_train:0': False}\n",
    "        predict_labels = self.sess.run('prediction_labels:0', feed_dict=feed_dict)\n",
    "        return predict_labels\n",
    "\n",
    "    def save(self, epoch, path='./model/cnn/'):\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path)\n",
    "        self.saver.save(self.sess, os.path.join(path, 'model.ckpt'), global_step=epoch)\n",
    "        print('Model saved in %s' % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"h1/Relu:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
      "Tensor(\"h1_pool/MaxPool:0\", shape=(?, 12, 12, 32), dtype=float32)\n",
      "Tensor(\"h2/Relu:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"h2_pool/MaxPool:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"h2_pool_flat:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"h3/Relu:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"h3_drop/cond/Merge:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"logits/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"prediction_labels:0\", shape=(?,), dtype=int32)\n",
      "Tensor(\"softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = ConvNNModel(random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 validation accuracy:  97.38\n",
      "Epoch:  2 validation accuracy:  98.25\n",
      "Epoch:  3 validation accuracy:  98.58\n",
      "Epoch:  4 validation accuracy:  98.76\n",
      "Epoch:  5 validation accuracy:  98.95\n",
      "Epoch:  6 validation accuracy:  98.96\n",
      "Epoch:  7 validation accuracy:  99.00\n",
      "Epoch:  8 validation accuracy:  99.06\n",
      "Epoch:  9 validation accuracy:  99.19\n",
      "Epoch: 10 validation accuracy:  99.13\n",
      "Epoch: 11 validation accuracy:  99.12\n",
      "Epoch: 12 validation accuracy:  99.24\n",
      "Epoch: 13 validation accuracy:  99.09\n",
      "Epoch: 14 validation accuracy:  99.26\n",
      "Epoch: 15 validation accuracy:  99.30\n",
      "Epoch: 16 validation accuracy:  99.27\n",
      "Epoch: 17 validation accuracy:  99.13\n",
      "Epoch: 18 validation accuracy:  99.25\n",
      "Epoch: 19 validation accuracy:  99.15\n",
      "Epoch: 20 validation accuracy:  99.23\n"
     ]
    }
   ],
   "source": [
    "model.train(training_set=(x_train_centered, y_train), validation_set=(x_test_centered, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in ./model/cnn/\n"
     ]
    }
   ],
   "source": [
    "model.save(epoch=model.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
